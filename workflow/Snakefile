import pandas as pd
from pathlib import Path

# Figure out the root dir of the project
cwd = Path.cwd()
if cwd.name == 'workflow':
	project_dir = str(cwd.parent)
else:
	project_dir = str(cwd)

# Load the user configuration
configfile: f"{project_dir}/workflow/config.yaml"

# Various paths we will be using in this analysis pipeline
data_dir = config['data_dir']
workflow_dir = f'{project_dir}/workflow'
code_dir = f'{project_dir}/code'
gencode_dir = f'{data_dir}/GENCODE_TSS'
blacklists_dir = f'{data_dir}/blacklists'
intervals_dir= f'{data_dir}/intervals_bed_{config["binSize"]}'


# Big list of all the samples
all_samples = pd.read_csv(f'{workflow_dir}/samples.tsv', sep='\t').sort_index()
def all_data_types(cell_line):
	return all_samples.dropna().query(f"cell_line=='{cell_line}'").data_type.unique()

rule all:
	input:
		expand(f'{data_dir}/{{cell_line}}/bed_shifted_RFECS/{{data_type}}.bed', data_type=all_data_types, cell_line=['K562', 'Gm12878']),
		f'{gencode_dir}/GR_Gencode_TSS.RDS'

include: 'preprocessing.smk'
include: 'train_predict.smk'
